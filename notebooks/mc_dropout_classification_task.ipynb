{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b08456e8",
   "metadata": {
    "id": "b08456e8"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "_bfz6jBMBRRE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_bfz6jBMBRRE",
    "outputId": "d62ce682-aec9-4fe0-f78b-892086e3cafe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -q flax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b781dfc2",
   "metadata": {
    "id": "b781dfc2"
   },
   "outputs": [],
   "source": [
    "import flax\n",
    "import flax.linen as nn\n",
    "from flax.core import unfreeze\n",
    "\n",
    "from flax.training import train_state \n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import optax\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow.keras.datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4158a2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5351b28e",
   "metadata": {
    "id": "5351b28e"
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \n",
    "    @nn.compact\n",
    "    def __call__(self, x, deterministic):\n",
    "        \n",
    "        #1 layer\n",
    "        x = nn.Conv(features=6, kernel_size=(5,5), name=\"conv2d_1\")(x)\n",
    "        # x = nn.tanh(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2))\n",
    "        \n",
    "        #2 layer\n",
    "        x = nn.Conv(features=16, kernel_size=(5,5), name=\"conv2d_2\")(x)\n",
    "        # x = nn.tanh(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2))\n",
    "        \n",
    "        #3 layer\n",
    "        x = nn.Conv(features=120, kernel_size=(5,5), name=\"conv2d_3\")(x)\n",
    "        # x = nn.tanh(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.avg_pool(x, window_shape=(2,2))\n",
    "        \n",
    "        x = x.reshape((x.shape[0],-1)) #flatten\n",
    "        #4 fully connected layer\n",
    "        x = nn.Dense(84, name=\"Dense_1_84\")(x)\n",
    "        # x = nn.tanh(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dropout(rate=0.5, deterministic= deterministic)(x)\n",
    "\n",
    "        #5 fully connected layer\n",
    "        x = nn.Dense(10, name=\"Dense_2_10\")(x)\n",
    "        # x = nn.softmax(x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51c7bfdc",
   "metadata": {
    "id": "51c7bfdc"
   },
   "outputs": [],
   "source": [
    "def get_datasets():\n",
    "    train_dataset, test_dataset = tfds.mnist.load_data()\n",
    "    X_train, y_train = train_dataset\n",
    "    x_test, y_test = test_dataset\n",
    "    \n",
    "    X_train = jnp.array(X_train/255)\n",
    "    x_test = jnp.array(x_test/255)\n",
    "    \n",
    "    X_train = X_train[..., jnp.newaxis]\n",
    "    x_test = x_test[..., jnp.newaxis]\n",
    "    \n",
    "    return [X_train, y_train], [x_test, y_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa5c3c30",
   "metadata": {
    "id": "fa5c3c30"
   },
   "outputs": [],
   "source": [
    "def cross_entropy_loss(params, x, y, rng, deterministic=False):\n",
    "    labels_onehot = jax.nn.one_hot(y, num_classes=10)\n",
    "    logits = model.apply(params, x, deterministic=deterministic, rngs={\"dropout\": rng})\n",
    "    return optax.softmax_cross_entropy(logits=logits, labels=labels_onehot).mean(), logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "YQmroxnkWGxN",
   "metadata": {
    "id": "YQmroxnkWGxN"
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(params, x, y, rng):\n",
    "    loss, logits = cross_entropy_loss(params, x, y, rng, deterministic=True)\n",
    "    accuracy = jnp.mean(jnp.argmax(logits, -1) == y)\n",
    "    return accuracy.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b413f812",
   "metadata": {
    "id": "b413f812"
   },
   "outputs": [],
   "source": [
    "def fit(params, X, Y, batch_size, learning_rate=0.1, epochs=100, verbose=False):\n",
    "    # opt = optax.adamw(learning_rate=learning_rate)\n",
    "    opt = optax.sgd(learning_rate, 0.0001)\n",
    "    opt_state = opt.init(params)\n",
    "    \n",
    "    lg_fn = jax.value_and_grad(cross_entropy_loss, has_aux=True)\n",
    "    \n",
    "    rng, _ = jax.random.split(jax.random.PRNGKey(0))\n",
    "    losses = []\n",
    "\n",
    "    train_ds_size = len(X)\n",
    "    steps_per_epoch = train_ds_size // batch_size\n",
    "\n",
    "    for i in range(epochs):\n",
    "        rng , _ = jax.random.split(rng)\n",
    "        @jax.jit\n",
    "        def one_step(params, x, y, opt_state):\n",
    "            (loss_val, logits), grads = lg_fn(params, x, y, rng)\n",
    "            updates, opt_state = opt.update(grads, opt_state, params)\n",
    "            params = optax.apply_updates(params, updates)\n",
    "            return params, opt_state, loss_val, logits\n",
    "\n",
    "        # _ , rng = jax.random.split(rng)\n",
    "        perms = jax.random.permutation(rng, train_ds_size)\n",
    "        perms = perms[:steps_per_epoch * batch_size]  # skip incomplete batch\n",
    "        perms = perms.reshape((steps_per_epoch, batch_size))\n",
    "        accuracy = []\n",
    "\n",
    "        for perm in perms:\n",
    "          x, y = X[perm], Y[perm]\n",
    "          params, opt_state, loss_val, logits =  one_step(params, x, y, opt_state)\n",
    "          accuracy.append(compute_accuracy(params, x, y, rng))\n",
    "\n",
    "        if verbose and i % (epochs/10) == 0:\n",
    "            print('train epoch: %d, loss: %.4f, accuracy: %.2f' % (i, loss_val, jnp.mean(jnp.array(accuracy))))\n",
    "    return params,losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36bc0c7d",
   "metadata": {
    "id": "36bc0c7d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    }
   ],
   "source": [
    "train_ds, test_ds = get_datasets()\n",
    "X_train, y_train = train_ds\n",
    "x_test, y_test = test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a3f64c6",
   "metadata": {
    "id": "3a3f64c6"
   },
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "rng = jax.random.PRNGKey(0)\n",
    "rng, init_rng = jax.random.split(rng)\n",
    "model = LeNet()\n",
    "# model = CNN()\n",
    "params = model.init(init_rng, jnp.ones([1, 28, 28, 1]), deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab20c3d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eab20c3d",
    "outputId": "375ecdfc-0bfe-4c9a-edd3-be6fd4abaa19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train epoch: 0, loss: 0.0997, accuracy: 0.96\n",
      "train epoch: 1, loss: 0.0081, accuracy: 1.00\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m params, losses \u001b[38;5;241m=\u001b[39m \u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mfit\u001b[0;34m(params, X, Y, batch_size, learning_rate, epochs, verbose)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m perm \u001b[38;5;129;01min\u001b[39;00m perms:\n\u001b[1;32m     30\u001b[0m   x, y \u001b[38;5;241m=\u001b[39m X[perm], Y[perm]\n\u001b[0;32m---> 31\u001b[0m   params, opt_state, loss_val, logits \u001b[38;5;241m=\u001b[39m  \u001b[43mone_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m   accuracy\u001b[38;5;241m.\u001b[39mappend(compute_accuracy(params, x, y, rng))\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose \u001b[38;5;129;01mand\u001b[39;00m i \u001b[38;5;241m%\u001b[39m (epochs\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/flax/core/frozen_dict.py:159\u001b[0m, in \u001b[0;36mFrozenDict.tree_unflatten\u001b[0;34m(cls, _, data)\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[38;5;124;03m\"\"\"Flattens this FrozenDict.\u001b[39;00m\n\u001b[1;32m    153\u001b[0m \n\u001b[1;32m    154\u001b[0m \u001b[38;5;124;03m  Returns:\u001b[39;00m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;124;03m    A flattened version of this FrozenDict instance.\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dict,), ()\n\u001b[0;32m--> 159\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtree_unflatten\u001b[39m(\u001b[38;5;28mcls\u001b[39m, _, data):\n\u001b[1;32m    161\u001b[0m   \u001b[38;5;66;03m# data is already deep copied due to tree map mechanism\u001b[39;00m\n\u001b[1;32m    162\u001b[0m   \u001b[38;5;66;03m# we can skip the deep copy in the constructor\u001b[39;00m\n\u001b[1;32m    163\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39mdata, __unsafe_skip_copy__\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params, losses = fit(params, X_train, y_train, 64, epochs = 10, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca72a10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c298e76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = jnp.load(\"params.npy\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "059f6252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'params'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d31de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img = X_train[y_train == 1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ccf08cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_img = rotate(one_img, 30, reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = []\n",
    "for i in range(12):\n",
    "#     plt.imshow(rotate(one_img, 6*i, reshape=False))\n",
    "    images.append(jnp.array(rotate(one_img, 6*i, reshape=False)))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb598d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = jnp.array(images)\n",
    "labels = model.apply(params, images, deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dccfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d81655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845d5dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mc_dropout_classification_task.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
